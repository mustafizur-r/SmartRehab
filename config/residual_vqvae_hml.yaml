exp:
  root_ckpt_dir: './checkpoint_dir'
  root_log_dir: './log'
  # name: hml_hrvq_nq2_263_nb512_fk0_gl0_ex0.5_attn
  name: test
  device: 'cuda:0'
  is_continue: False
  is_train: True
  seed: 10306


data:
  name: 'humanml3d'
  unit_length: 4
  root_dir: './HumanML3D'
  joint_num: 22
  dim_pose: 263 #296 #here we use all features
  fps: 20
  max_motion_length: 196
  motion_length: 128
  max_text_length: 20
  min_motion_length: 40

quantizer:
  code_dim: 512
  nb_code: 512
  scales: [8, 4, 2, 1] #v1
  # scales: [16, 8, 4, 2, 1] #v3
  # scales: [32, 16, 8, 4, 2, 1] #v4
  # scales: [32, 20, 16, 10, 8, 6, 4, 3, 2, 1]
  # scales: [32, 16, 10.6, 8, 5.3, 4, 3, 2, 1.33, 1] #v2
  quantize_dropout_prob: 0
  num_quantizers: 6
  shared_codebook: False
  share_quant_resi: 4
  quant_resi: 0
  start_drop: -1
  version: 'v2'
  mu: 0.99

model:
  down_t: 2
  stride_t: 2
  width: 512
  depth: 3
  dilation_growth_rate: 3 
  vq_act: 'relu'
  use_attn: True
  vq_norm: None

training:
  # batch_size: 256
  # max_epoch: 50
  batch_size: 256
  max_epoch: 1000
  lambda_fk: 0
  lambda_commit: 0.02
  lambda_global: 0
  lambda_expicit: 0.5
  ema: False
  weight_decay: 0.0
  lr: 3.0e-4
  milestones: [300, 700]
  gamma: 0.3
  warm_up_iter: 2000
  log_every: 10
  save_latest: 500
  # eval_every_e: 1
  eval_every_e: 10
  recons_loss: 'l1_smooth'

